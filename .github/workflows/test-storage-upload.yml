name: Test Storage Upload

on:
  workflow_dispatch:  # Manual trigger only

env:
  PYTHON_VERSION: '3.11'

jobs:
  test-upload:
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install supabase

      - name: Test Storage Upload
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          python - <<'EOF'
          import os
          from pathlib import Path
          from supabase import create_client, Client

          print("=" * 60)
          print("TEST UPLOAD SQL FILES → SUPABASE STORAGE")
          print("=" * 60)

          url = os.getenv('SUPABASE_URL')
          key = os.getenv('SUPABASE_SERVICE_ROLE_KEY')

          if not url or not key:
              print("❌ Missing credentials!")
              exit(1)

          print(f"\nProject: {url}")
          print("Using: Service Role Key (bypasses RLS)")

          # Create client with service role key
          supabase: Client = create_client(url, key)

          print("\n[1] Reading SQL file from repo...")

          # Read a real SQL file from TABLES/
          sql_file = Path('TABLES/01_REFERENCES/company_roles.sql')

          if not sql_file.exists():
              print(f"❌ File not found: {sql_file}")
              exit(1)

          with open(sql_file, 'r', encoding='utf-8') as f:
              sql_content = f.read()

          print(f"  ✓ Read {sql_file.name} ({len(sql_content)} chars)")
          print(f"  Preview: {sql_content[:100]}...")

          print("\n[2] Uploading to Storage...")

          try:
              with open(sql_file, 'rb') as f:
                  response = supabase.storage.from_('sql-scripts').upload(
                      path=f'01_REFERENCES/{sql_file.name}',
                      file=f,
                      file_options={'content-type': 'text/plain', 'upsert': 'true'}
                  )

              print(f"  ✓ Uploaded to: 01_REFERENCES/{sql_file.name}")

              print("\n[3] Verifying upload...")

              # List files in bucket
              files = supabase.storage.from_('sql-scripts').list('01_REFERENCES')
              print(f"  ✓ Files in 01_REFERENCES/:")
              for file in files:
                  print(f"    - {file['name']}")

              # Download to verify
              file_data = supabase.storage.from_('sql-scripts').download(f'01_REFERENCES/{sql_file.name}')
              downloaded_content = file_data.decode('utf-8')

              if downloaded_content == sql_content:
                  print(f"  ✓ Content verified! ({len(downloaded_content)} chars)")
              else:
                  print("  ⚠ Content mismatch!")

              print("\n" + "=" * 60)
              print("✅ SUCCESS!")
              print("GitHub Actions → Supabase Storage fonctionne!")
              print("Prochaine étape: Edge Function pour exécuter le SQL")
              print("=" * 60)

          except Exception as e:
              print("\n" + "=" * 60)
              print("❌ ÉCHEC")
              print(f"Erreur: {str(e)}")
              import traceback
              traceback.print_exc()
              print("=" * 60)
              exit(1)
          EOF

